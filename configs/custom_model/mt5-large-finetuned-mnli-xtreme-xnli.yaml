## below parameters are self-explanatory
model_name: "alan-turing-institute/mt5-large-finetuned-mnli-xtreme-xnli"
model_type: "t5" ## you can only have following types: "encode-decode","decoder-only","bart","discriminative","shared","hybrid","t5",
decoder_model_name: null
model_path: null ## provide the path if you have custom trained model using transformers library
tie_embeddings: false
label: null
tie_encoder_decoder: false

additional_model_inputs:
  output_scores: true
  return_dict_in_generate: true
  num_beams: 1

tokenizer:
  model_name: ${..model_name} ## only specify the name from huggingface if it's different than the actual  model
  label2id: ## this will vary based on the evaluation data, please refer to the your selected dataset config
    contradiction: "_2"
    neutral: "▁1"
    entailment: "▁0"
  args:
    truncation: true

## use following dataset pre-processing steps
data_processing:
  header: null ## prompt header for input data?
  footer: null ## prompt header for signling output?
  seprator: " " ## what is seperator token? leave `null` for generative models
  columns:
    premise: "xnli: premise:"
    hypothesis: "hypothesis:"