## below parameters are self-explanatory
model_name: "navteca/bart-large-mnli"
model_type: "discriminative" ## you can only have following types: "encode-decode","decoder-only","bart","discriminative","shared","hybrid","t5",
decoder_model_name: null
model_path: null ## provide the path if you have custom trained model using transformers library
tie_embeddings: false
label: null
tie_encoder_decoder: false
pipeline: "zero-shot-classification"

additional_model_inputs:
  multi_label: false

tokenizer:
  model_name: ${..model_name} ## only specify the name from huggingface if it's different than the actual  model
  label2id: ## this will vary based on the evaluation data, please refer to the your selected dataset config
    contradiction: 0
    neutral: 1
    entailment: 2
  args:
    truncation: true

## use following dataset pre-processing steps
data_processing:
  header: null ## prompt header for input data?
  footer: null ## prompt header for signling output?
  separator: " " ## what is separator token? leave `null` for generative models
  columns:
    premise: "xnli: premise:"
    hypothesis: "hypothesis:"
